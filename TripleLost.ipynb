{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.5.6-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torch>=2.1.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from pytorch-lightning) (2.7.0+cu128)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from pytorch-lightning) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>5.4 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from pytorch-lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.1)\n",
      "Collecting torchmetrics>0.7.0 (from pytorch-lightning)\n",
      "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from pytorch-lightning) (24.2)\n",
      "Requirement already satisfied: typing-extensions>4.5.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from pytorch-lightning) (4.12.2)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading aiohttp-3.13.2-cp312-cp312-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-win_amd64.whl.metadata (77 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (78.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning) (3.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from torchmetrics>0.7.0->pytorch-lightning) (2.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (2.1.5)\n",
      "Downloading pytorch_lightning-2.5.6-py3-none-any.whl (831 kB)\n",
      "   ---------------------------------------- 0.0/831.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 831.6/831.6 kB 35.6 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.13.2-cp312-cp312-win_amd64.whl (453 kB)\n",
      "Downloading multidict-6.7.0-cp312-cp312-win_amd64.whl (46 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-win_amd64.whl (87 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Downloading propcache-0.4.1-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
      "   ---------------------------------------- 0.0/983.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 983.2/983.2 kB 45.1 MB/s eta 0:00:00\n",
      "Installing collected packages: propcache, multidict, lightning-utilities, frozenlist, attrs, aiohappyeyeballs, yarl, aiosignal, torchmetrics, aiohttp, pytorch-lightning\n",
      "\n",
      "   ------- --------------------------------  2/11 [lightning-utilities]\n",
      "   -------------- -------------------------  4/11 [attrs]\n",
      "   ----------------------------- ----------  8/11 [torchmetrics]\n",
      "   ----------------------------- ----------  8/11 [torchmetrics]\n",
      "   ----------------------------- ----------  8/11 [torchmetrics]\n",
      "   ----------------------------- ----------  8/11 [torchmetrics]\n",
      "   ----------------------------- ----------  8/11 [torchmetrics]\n",
      "   ----------------------------- ----------  8/11 [torchmetrics]\n",
      "   ----------------------------- ----------  8/11 [torchmetrics]\n",
      "   ----------------------------- ----------  8/11 [torchmetrics]\n",
      "   ----------------------------- ----------  8/11 [torchmetrics]\n",
      "   ----------------------------- ----------  8/11 [torchmetrics]\n",
      "   ----------------------------- ----------  8/11 [torchmetrics]\n",
      "   -------------------------------- -------  9/11 [aiohttp]\n",
      "   -------------------------------- -------  9/11 [aiohttp]\n",
      "   -------------------------------- -------  9/11 [aiohttp]\n",
      "   ------------------------------------ --- 10/11 [pytorch-lightning]\n",
      "   ------------------------------------ --- 10/11 [pytorch-lightning]\n",
      "   ------------------------------------ --- 10/11 [pytorch-lightning]\n",
      "   ------------------------------------ --- 10/11 [pytorch-lightning]\n",
      "   ------------------------------------ --- 10/11 [pytorch-lightning]\n",
      "   ------------------------------------ --- 10/11 [pytorch-lightning]\n",
      "   ------------------------------------ --- 10/11 [pytorch-lightning]\n",
      "   ------------------------------------ --- 10/11 [pytorch-lightning]\n",
      "   ------------------------------------ --- 10/11 [pytorch-lightning]\n",
      "   ---------------------------------------- 11/11 [pytorch-lightning]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 attrs-25.4.0 frozenlist-1.8.0 lightning-utilities-0.15.2 multidict-6.7.0 propcache-0.4.1 pytorch-lightning-2.5.6 torchmetrics-1.8.2 yarl-1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-lightning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-metric-learning\n",
      "  Downloading pytorch_metric_learning-2.9.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from pytorch-metric-learning) (2.1.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from pytorch-metric-learning) (1.7.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from pytorch-metric-learning) (2.7.0+cu128)\n",
      "Requirement already satisfied: tqdm in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from pytorch-metric-learning) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from torch>=1.6.0->pytorch-metric-learning) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from sympy>=1.13.3->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from scikit-learn->pytorch-metric-learning) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from tqdm->pytorch-metric-learning) (0.4.6)\n",
      "Downloading pytorch_metric_learning-2.9.0-py3-none-any.whl (127 kB)\n",
      "Installing collected packages: pytorch-metric-learning\n",
      "Successfully installed pytorch-metric-learning-2.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-metric-learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.1.2-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from xgboost) (2.1.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\i21326\\.conda\\envs\\vs\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Downloading xgboost-3.1.2-py3-none-win_amd64.whl (72.0 MB)\n",
      "   ---------------------------------------- 0.0/72.0 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 23.9/72.0 MB 116.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 48.0/72.0 MB 117.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  71.8/72.0 MB 117.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 72.0/72.0 MB 102.0 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 0) IMPORTS\n",
    "# ================================================================\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_metric_learning.losses import TripletMarginLoss\n",
    "from pytorch_metric_learning.miners import TripletMarginMiner\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases detectadas: ['Abutilon Indicum', 'Aloe barbadensis miller', 'Calotropis gigantea', 'Canna indica', 'Cissus quadrangularis', 'Curcuma longa', 'Eclipta prostrate', 'Eichhornia Crassipes', 'Hibiscus Rosasinensis', 'Ixora coccinea', 'Justica adhatoda', 'Murraya koenigii', 'Ocimum tenuiflorum', 'Ouretlanata', 'Phyllanthus amarus', 'Ricinus communis', 'Senna Atriculata', 'Sesbania grandiflora', 'Trifolium Repens', 'Ziziphus mauritiana']\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 1) DATA TRANSFORMS + DATASET (YA SEPARADO)\n",
    "# ================================================================\n",
    "DATASET_ROOT = r\"D:\\DEEp\\deep\\dataset_split\"\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(DATASET_ROOT, \"train\"), transform=train_transform)\n",
    "val_dataset   = datasets.ImageFolder(os.path.join(DATASET_ROOT, \"val\"),   transform=test_transform)\n",
    "test_dataset  = datasets.ImageFolder(os.path.join(DATASET_ROOT, \"test\"),  transform=test_transform)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"Clases detectadas:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\I21326/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 97.8M/97.8M [00:00<00:00, 119MB/s]\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 2) SIAMESE NETWORK (EMBEDDING)\n",
    "# ================================================================\n",
    "class SiameseBackbone(nn.Module):\n",
    "    def __init__(self, embedding_size=128):\n",
    "        super().__init__()\n",
    "        self.backbone = models.resnet50(weights=\"DEFAULT\")\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, embedding_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "siamese = SiameseBackbone().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "c:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA RTX 6000 Ada Generation') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model     | SiameseBackbone    | 23.8 M | train\n",
      "1 | miner     | TripletMarginMiner | 0      | train\n",
      "2 | loss_func | TripletMarginLoss  | 0      | train\n",
      "---------------------------------------------------------\n",
      "23.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.8 M    Total params\n",
      "95.081    Total estimated model params size (MB)\n",
      "157       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:428: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Please call `iter(combined_loader)` first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:49\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(*args, **kwargs)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:598\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    592\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    593\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    594\u001b[39m     ckpt_path,\n\u001b[32m    595\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    596\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    597\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[38;5;28mself\u001b[39m._run(model, ckpt_path=ckpt_path)\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1011\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1008\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m results = \u001b[38;5;28mself\u001b[39m._run_stage()\n\u001b[32m   1013\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1055\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m     \u001b[38;5;28mself\u001b[39m.fit_loop.run()\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:208\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28mself\u001b[39m.setup_data()\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.skip:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:275\u001b[39m, in \u001b[36m_FitLoop.setup_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28mself\u001b[39m._data_fetcher.setup(combined_loader)\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m._data_fetcher)  \u001b[38;5;66;03m# creates the iterator inside the fetcher\u001b[39;00m\n\u001b[32m    276\u001b[39m max_batches = sized_len(combined_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:105\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33m_PrefetchDataFetcher\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    107\u001b[39m         \u001b[38;5;66;03m# ignore pre-fetching, it's not necessary\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:52\u001b[39m, in \u001b[36m_DataFetcher.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[33m\"\u001b[39m\u001b[33m_DataFetcher\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28mself\u001b[39m.iterator = \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m.combined_loader)\n\u001b[32m     53\u001b[39m     \u001b[38;5;28mself\u001b[39m.reset()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:351\u001b[39m, in \u001b[36mCombinedLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    350\u001b[39m iterator = \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;28mself\u001b[39m.flattened, \u001b[38;5;28mself\u001b[39m._limits)\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m \u001b[38;5;28miter\u001b[39m(iterator)\n\u001b[32m    352\u001b[39m \u001b[38;5;28mself\u001b[39m._iterator = iterator\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:92\u001b[39m, in \u001b[36m_MaxSizeCycle.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Self:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m._consumed = [\u001b[38;5;28;01mFalse\u001b[39;00m] * \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.iterables)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:43\u001b[39m, in \u001b[36m_ModeIterator.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Self:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28mself\u001b[39m.iterators = [\u001b[38;5;28miter\u001b[39m(iterable) \u001b[38;5;28;01mfor\u001b[39;00m iterable \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iterables]\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m._idx = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:493\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_iterator()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:424\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    423\u001b[39m \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1171\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1171\u001b[39m w.start()\n\u001b[32m   1172\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\multiprocessing\\process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28mself\u001b[39m._Popen(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\multiprocessing\\context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_context.get_context().Process._Popen(process_obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\multiprocessing\\context.py:337\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Popen(process_obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     94\u001b[39m     reduction.dump(prep_data, to_child)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     reduction.dump(process_obj, to_child)\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\multiprocessing\\reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m ForkingPickler(file, protocol).dump(obj)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m torch.optim.Adam(\u001b[38;5;28mself\u001b[39m.parameters(), lr=\u001b[38;5;28mself\u001b[39m.lr)\n\u001b[32m     29\u001b[39m triplet_trainer = pl.Trainer(max_epochs=\u001b[32m5\u001b[39m, accelerator=device, log_every_n_steps=\u001b[32m20\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m triplet_trainer.fit(TripletLightning(siamese), train_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:560\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    558\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m call._call_and_handle_interrupt(\n\u001b[32m    561\u001b[39m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[32m    562\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:62\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     60\u001b[39m signal.signal(signal.SIGINT, signal.SIG_IGN)\n\u001b[32m     61\u001b[39m _interrupt(trainer, exception)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m trainer._teardown()\n\u001b[32m     63\u001b[39m launcher = trainer.strategy.launcher\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1038\u001b[39m, in \u001b[36mTrainer._teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1036\u001b[39m \u001b[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1038\u001b[39m     loop.teardown()\n\u001b[32m   1039\u001b[39m \u001b[38;5;28mself\u001b[39m._logger_connector.teardown()\n\u001b[32m   1040\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.teardown()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:505\u001b[39m, in \u001b[36m_FitLoop.teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mteardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    504\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m         \u001b[38;5;28mself\u001b[39m._data_fetcher.teardown()\n\u001b[32m    506\u001b[39m         \u001b[38;5;28mself\u001b[39m._data_fetcher = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    507\u001b[39m     \u001b[38;5;28mself\u001b[39m.epoch_loop.teardown()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:80\u001b[39m, in \u001b[36m_DataFetcher.teardown\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mteardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28mself\u001b[39m.reset()\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._combined_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     82\u001b[39m         \u001b[38;5;28mself\u001b[39m._combined_loader.reset()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:142\u001b[39m, in \u001b[36m_PrefetchDataFetcher.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28msuper\u001b[39m().reset()\n\u001b[32m    143\u001b[39m     \u001b[38;5;28mself\u001b[39m.batches = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:76\u001b[39m, in \u001b[36m_DataFetcher.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# teardown calls `reset()`, and if it happens early, `combined_loader` can still be None\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._combined_loader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28mself\u001b[39m.length = sized_len(\u001b[38;5;28mself\u001b[39m.combined_loader)\n\u001b[32m     77\u001b[39m     \u001b[38;5;28mself\u001b[39m.done = \u001b[38;5;28mself\u001b[39m.length == \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\lightning_fabric\\utilities\\data.py:52\u001b[39m, in \u001b[36msized_len\u001b[39m\u001b[34m(dataloader)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Try to get the length of an object, return ``None`` otherwise.\"\"\"\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m# try getting the length\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     length = \u001b[38;5;28mlen\u001b[39m(dataloader)  \u001b[38;5;66;03m# type: ignore [arg-type]\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[32m     54\u001b[39m     length = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\I21326\\.conda\\envs\\VS\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:358\u001b[39m, in \u001b[36mCombinedLoader.__len__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute the number of batches.\"\"\"\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPlease call `iter(combined_loader)` first.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator)\n",
      "\u001b[31mRuntimeError\u001b[39m: Please call `iter(combined_loader)` first."
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# 3) PYTORCH LIGHTNING TRAINER PARA TRIPLET LOSS\n",
    "# ================================================================\n",
    "class TripletLightning(pl.LightningModule):\n",
    "    def __init__(self, model, lr=1e-4, margin=0.2):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.miner = TripletMarginMiner(margin=margin, type_of_triplets=\"semihard\")\n",
    "        self.loss_func = TripletMarginLoss(margin=margin)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        embeddings = self(imgs)\n",
    "\n",
    "        hard_pairs = self.miner(embeddings, labels)\n",
    "        loss = self.loss_func(embeddings, labels, hard_pairs)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "triplet_trainer = pl.Trainer(max_epochs=5, accelerator=device, log_every_n_steps=20)\n",
    "triplet_trainer.fit(TripletLightning(siamese), train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 4) CLASIFICADOR FC CONGELANDO EL BACKBONE\n",
    "# ================================================================\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, backbone, emb_size, num_classes):\n",
    "        super().__init__()\n",
    "        for p in backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.fc = nn.Linear(emb_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            emb = self.backbone(x)\n",
    "        return self.fc(emb)\n",
    "\n",
    "classifier = Classifier(siamese, 128, num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classifier.fc.parameters(), lr=1e-3)\n",
    "\n",
    "# -------- Entrenamiento del clasificador --------\n",
    "for epoch in range(8):\n",
    "    classifier.train()\n",
    "    running_loss = 0\n",
    "    for img, lbl in train_loader:\n",
    "        img, lbl = img.to(device), lbl.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = classifier(img)\n",
    "        loss = criterion(out, lbl)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 5) EVALUACIN DEL CLASIFICADOR FC\n",
    "# ================================================================\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    preds, labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            out = model(x)\n",
    "            p = out.argmax(1).cpu().numpy()\n",
    "            preds.extend(p)\n",
    "            labels.extend(y.numpy())\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1  = f1_score(labels, preds, average=\"macro\")\n",
    "    return acc, f1, labels, preds\n",
    "\n",
    "acc, f1, y_true, y_pred = evaluate(classifier, test_loader)\n",
    "\n",
    "print(\"Accuracy Clasificador FC:\", acc)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, annot=False, cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Matriz de Confusi贸n - FC\")\n",
    "plt.xlabel(\"Predicci贸n\")\n",
    "plt.ylabel(\"Verdad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 6) EXTRAER EMBEDDINGS (PARA XGBOOST)\n",
    "# ================================================================\n",
    "def extract_embeddings(model, loader):\n",
    "    model.eval()\n",
    "    all_emb, all_lbl = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            emb = model(x).cpu().numpy()\n",
    "            all_emb.append(emb)\n",
    "            all_lbl.append(y.numpy())\n",
    "\n",
    "    return np.vstack(all_emb), np.hstack(all_lbl)\n",
    "\n",
    "train_emb, train_lbl = extract_embeddings(siamese, train_loader)\n",
    "test_emb,  test_lbl  = extract_embeddings(siamese, test_loader)\n",
    "\n",
    "print(\"Embeddings shape:\", train_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 7) XGBOOST PARA CLASIFICAR EMBEDDINGS\n",
    "# ================================================================\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "xgb.fit(train_emb, train_lbl)\n",
    "xgb_preds = xgb.predict(test_emb)\n",
    "\n",
    "acc_xgb = accuracy_score(test_lbl, xgb_preds)\n",
    "f1_xgb  = f1_score(test_lbl, xgb_preds, average=\"macro\")\n",
    "\n",
    "print(\" XGBoost Accuracy:\", acc_xgb)\n",
    "print(\" XGBoost F1-score:\", f1_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 8) MATRIZ DE CONFUSIN XGBOOST\n",
    "# ================================================================\n",
    "cm = confusion_matrix(test_lbl, xgb_preds)\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(cm, annot=False, cmap=\"Greens\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Matriz de Confusi贸n - XGBoost\")\n",
    "plt.xlabel(\"Predicci贸n\")\n",
    "plt.ylabel(\"Verdad\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
